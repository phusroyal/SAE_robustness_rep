{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83addd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"https_proxy\"] = \"http://xen03.iitd.ac.in:3128\"\n",
    "os.environ[\"http_proxy\"] = \"http://xen03.iitd.ac.in:3128\"\n",
    "\n",
    "import sys\n",
    "# sys.path.append('../sae')\n",
    "from sae import Sae\n",
    "from utils import *\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, LlamaForCausalLM\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81a5004c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c98b5ad4585640869b5af8ab20143172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import model\n",
    "model_type = 'gemma2-2b'\n",
    "layer_num = 20\n",
    "device = 'cpu'\n",
    "model, tokenizer, sae = load_model_and_sae(model_type, layer_num, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5477cb3",
   "metadata": {},
   "source": [
    "# Random analysis of the SAE robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6be9741a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_raw_text = 'The film explores love and trauma through non-linear storytelling, blending magical realism with emotionally raw performances'\n",
    "x1_raw = tokenizer(x1_raw_text, return_tensors=\"pt\")['input_ids'].to(device)\n",
    "x1_raw_preprocessed = tokenizer(x1_raw_text + \"\\nThe previous text is about\", \n",
    "                                return_tensors=\"pt\")['input_ids'].to(device)\n",
    "h1_raw = model(x1_raw_preprocessed, output_hidden_states=True).hidden_states[layer_num + 1][0][-1].detach()\n",
    "\n",
    "x2_raw_text = \"The film explores love and trauma through non-linear storytelling, blending magical realism with emotionally raw performancesHacker Encryption implementations\"\n",
    "x2_raw = tokenizer(x2_raw_text, return_tensors=\"pt\")['input_ids'].to(device)\n",
    "x2_raw_preprocessed = tokenizer(x2_raw_text + \"\\nThe previous text is about\", \n",
    "                                return_tensors=\"pt\")['input_ids'].to(device)\n",
    "h2_raw = model(x2_raw_preprocessed, output_hidden_states=True).hidden_states[layer_num + 1][0][-1].detach()\n",
    "\n",
    "x3_raw_text = \"Encryption secures sensitive digital communication by converting readable data into unreadable ciphertext\"\n",
    "x3_raw = tokenizer(x3_raw_text, return_tensors=\"pt\")['input_ids'].to(device)\n",
    "x3_raw_preprocessed = tokenizer(x3_raw_text + \"\\nThe previous text is about\", \n",
    "                                return_tensors=\"pt\")['input_ids'].to(device)\n",
    "h3_raw = model(x3_raw_preprocessed, output_hidden_states=True).hidden_states[layer_num + 1][0][-1].detach()\n",
    "\n",
    "base_raw_sent = \"This is a base sentence for comparison\"\n",
    "base_raw = tokenizer(base_raw_sent, return_tensors=\"pt\")['input_ids'].to(device)\n",
    "base_raw_preprocessed = tokenizer(base_raw_sent + \"\\nThe previous text is about\", \n",
    "                                return_tensors=\"pt\")['input_ids'].to(device)\n",
    "h_base_raw = model(base_raw_preprocessed, output_hidden_states=True).hidden_states[layer_num + 1][0][-1].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64a75bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_raw = F.layer_norm(h1_raw, h1_raw.shape[-1:])\n",
    "h2_raw = F.layer_norm(h2_raw, h2_raw.shape[-1:])\n",
    "h3_raw = F.layer_norm(h3_raw, h3_raw.shape[-1:])\n",
    "h_base_raw = F.layer_norm(h_base_raw, h_base_raw.shape[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "019e843f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between h1_raw and h2_raw: 0.8860180974006653\n",
      "Cosine similarity between h1_raw and h3_raw: 0.8103485703468323\n",
      "Cosine similarity between h2_raw and h3_raw: 0.9335434436798096\n",
      "------------------------------------------------------------\n",
      "Cosine similarity between h1_raw and base_raw: 0.860113263130188\n",
      "Cosine similarity between h2_raw and base_raw: 0.8216165900230408\n",
      "Cosine similarity between h3_raw and base_raw: 0.788619875907898\n",
      "Shape of h1_plt: torch.Size([2304])\n",
      "Hamming distance between h1 and h2: 595\n",
      "Hamming distance between h1 and h3: 743\n",
      "Hamming distance between h2 and h3: 412\n",
      "Hamming distance between h1 and base: 643\n",
      "Hamming distance between h2 and base: 744\n",
      "Hamming distance between h3 and base: 806\n",
      "Hamming distance between z1 and z2: 229\n",
      "Hamming distance between z1 and z3: 234\n",
      "Hamming distance between z2 and z3: 157\n",
      "Overlap score between s1 and s2: 0.4000000059604645\n",
      "Overlap score between s1 and s3: 0.3529411852359772\n",
      "Overlap score between s2 and s3: 0.6235294342041016\n"
     ]
    }
   ],
   "source": [
    "# cosine similarity of h1_raw and h2_raw and h3_raw\n",
    "cos_sim_h1_h2 = F.cosine_similarity(h1_raw, h2_raw, dim=-1)\n",
    "cos_sim_h1_h3 = F.cosine_similarity(h1_raw, h3_raw, dim=-1)\n",
    "cos_sim_h2_h3 = F.cosine_similarity(h2_raw, h3_raw, dim=-1)\n",
    "print(f\"Cosine similarity between h1_raw and h2_raw: {cos_sim_h1_h2.item()}\")\n",
    "print(f\"Cosine similarity between h1_raw and h3_raw: {cos_sim_h1_h3.item()}\")\n",
    "print(f\"Cosine similarity between h2_raw and h3_raw: {cos_sim_h2_h3.item()}\")\n",
    "\n",
    "print('---' * 20)\n",
    "\n",
    "# compare h1_raw, h2_raw, h3_raw with base_raw\n",
    "cos_sim_h1_base = F.cosine_similarity(h1_raw, h_base_raw, dim=-1)\n",
    "cos_sim_h2_base = F.cosine_similarity(h2_raw, h_base_raw, dim=-1)\n",
    "cos_sim_h3_base = F.cosine_similarity(h3_raw, h_base_raw, dim=-1)\n",
    "print(f\"Cosine similarity between h1_raw and base_raw: {cos_sim_h1_base.item()}\")\n",
    "print(f\"Cosine similarity between h2_raw and base_raw: {cos_sim_h2_base.item()}\")\n",
    "print(f\"Cosine similarity between h3_raw and base_raw: {cos_sim_h3_base.item()}\")\n",
    "\n",
    "\n",
    "\n",
    "def polytope(x):\n",
    "    \"\"\"\n",
    "    If value is greater than 0, then 1 else 0\n",
    "    \"\"\"\n",
    "    return (x > 0).float()\n",
    "\n",
    "h1_plt = polytope(h1_raw)\n",
    "h2_plt = polytope(h2_raw)\n",
    "h3_plt = polytope(h3_raw)\n",
    "base_plt = polytope(h_base_raw)\n",
    "\n",
    "# Print the shapes of the polytopes\n",
    "print(f\"Shape of h1_plt: {h1_plt.shape}\")\n",
    "\n",
    "# hamming distance\n",
    "hamming_distance = torch.sum(h1_plt != h2_plt).item()\n",
    "print(f\"Hamming distance between h1 and h2: {hamming_distance}\")\n",
    "\n",
    "hamming_distance = torch.sum(h1_plt != h3_plt).item()\n",
    "print(f\"Hamming distance between h1 and h3: {hamming_distance}\")\n",
    "\n",
    "hamming_distance = torch.sum(h2_plt != h3_plt).item()\n",
    "print(f\"Hamming distance between h2 and h3: {hamming_distance}\")\n",
    "\n",
    "hamming_distance = torch.sum(h1_plt != base_plt).item()\n",
    "print(f\"Hamming distance between h1 and base: {hamming_distance}\")\n",
    "\n",
    "hamming_distance = torch.sum(h2_plt != base_plt).item()\n",
    "print(f\"Hamming distance between h2 and base: {hamming_distance}\")\n",
    "\n",
    "hamming_distance = torch.sum(h3_plt != base_plt).item()\n",
    "print(f\"Hamming distance between h3 and base: {hamming_distance}\")\n",
    "\n",
    "k=170\n",
    "\n",
    "z1,s1,s1_acts = extract_sae_features(h1_raw, sae, model_type, k)\n",
    "z2,s2,s2_acts = extract_sae_features(h2_raw, sae, model_type, k)\n",
    "z3,s3,s3_acts = extract_sae_features(h3_raw, sae, model_type, k)\n",
    "# value in z1, z2, z3 are not 1 only\n",
    "# appy polytope\n",
    "z1_plt = polytope(z1)\n",
    "z2_plt = polytope(z2)\n",
    "z3_plt = polytope(z3)\n",
    "\n",
    "# hamming distance\n",
    "hamming_distance = torch.sum(z1_plt != z2_plt).item()\n",
    "print(f\"Hamming distance between z1 and z2: {hamming_distance}\")\n",
    "hamming_distance = torch.sum(z1_plt != z3_plt).item()  \n",
    "print(f\"Hamming distance between z1 and z3: {hamming_distance}\")\n",
    "hamming_distance = torch.sum(z2_plt != z3_plt).item()\n",
    "print(f\"Hamming distance between z2 and z3: {hamming_distance}\")\n",
    "\n",
    "# how about get overlap\n",
    "overlap_score = get_overlap(s1, s2)\n",
    "print(f\"Overlap score between s1 and s2: {overlap_score}\")\n",
    "overlap_score = get_overlap(s1, s3)\n",
    "print(f\"Overlap score between s1 and s3: {overlap_score}\")\n",
    "overlap_score = get_overlap(s2, s3)\n",
    "print(f\"Overlap score between s2 and s3: {overlap_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecd1fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01c1a3af",
   "metadata": {},
   "source": [
    "# Boundary Crossing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef2a938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3062a7ff",
   "metadata": {},
   "source": [
    "# Interpretation and Conclusions\n",
    "print(\"=== BOUNDARY CROSSING ANALYSIS CONCLUSIONS ===\\n\")\n",
    "\n",
    "if 'batch_results' in locals() and batch_results:\n",
    "    successful_results = {k: v for k, v in batch_results.items() if v.target_reached}\n",
    "    \n",
    "    if successful_results:\n",
    "        delta_norms = [r.delta_min for r in successful_results.values()]\n",
    "        mean_boundary_dist = np.mean(delta_norms)\n",
    "        std_boundary_dist = np.std(delta_norms)\n",
    "        \n",
    "        print(\"1. MARGIN ANALYSIS:\")\n",
    "        print(f\"   - Average minimal perturbation to cross boundary: {mean_boundary_dist:.6f}\")\n",
    "        print(f\"   - Standard deviation: {std_boundary_dist:.6f}\")\n",
    "        print(f\"   - This suggests SAE boundaries are {'close' if mean_boundary_dist < 0.1 else 'distant'}\")\n",
    "        \n",
    "        # Compare with typical input norms for context\n",
    "        if 'all_texts' in locals():\n",
    "            hidden_norms = []\n",
    "            for text in all_texts[:3]:  # Sample a few to get typical norms\n",
    "                h = tracer.get_hidden_representation(text, layer_num)\n",
    "                hidden_norms.append(h.norm().item())\n",
    "            avg_hidden_norm = np.mean(hidden_norms)\n",
    "            relative_perturbation = mean_boundary_dist / avg_hidden_norm\n",
    "            print(f\"   - Relative to input magnitude ({avg_hidden_norm:.2f}): {relative_perturbation:.4f} ({relative_perturbation*100:.2f}%)\")\n",
    "\n",
    "if 'concept_results' in locals() and concept_results:\n",
    "    print(\"\\n2. CONCEPT DISTANCE ANALYSIS:\")\n",
    "    \n",
    "    concept_distances = []\n",
    "    boundary_distances = []\n",
    "    ratios = []\n",
    "    \n",
    "    for data in concept_results.values():\n",
    "        concept_distances.extend([data['a_to_b_distance'], data['b_to_a_distance']])\n",
    "        boundary_distances.extend([data['a_boundary_distance'], data['b_boundary_distance']])\n",
    "        if data['distance_ratio_a'] != float('inf'):\n",
    "            ratios.append(data['distance_ratio_a'])\n",
    "        if data['distance_ratio_b'] != float('inf'):\n",
    "            ratios.append(data['distance_ratio_b'])\n",
    "    \n",
    "    if ratios:\n",
    "        mean_ratio = np.mean(ratios)\n",
    "        print(f\"   - Concept distances are {mean_ratio:.1f}x larger than single boundary distances\")\n",
    "        print(f\"   - This means crossing from Education→Technology requires crossing ~{mean_ratio:.0f} boundaries\")\n",
    "        \n",
    "        if mean_ratio > 3:\n",
    "            print(\"   - INTERPRETATION: Concepts are well-separated in SAE space\")\n",
    "        elif mean_ratio > 1.5:\n",
    "            print(\"   - INTERPRETATION: Moderate concept separation\")\n",
    "        else:\n",
    "            print(\"   - INTERPRETATION: Concepts may be close together (potential vulnerability)\")\n",
    "\n",
    "if 'feature_flips' in locals() and feature_flips:\n",
    "    print(\"\\n3. FEATURE VULNERABILITY:\")\n",
    "    vulnerable_features = len([f for f, counts in feature_flips.items() if counts['total'] >= 2])\n",
    "    total_features = len(original_code)  # Assuming this is available\n",
    "    vulnerability_rate = vulnerable_features / total_features if total_features > 0 else 0\n",
    "    \n",
    "    print(f\"   - {vulnerable_features} out of {total_features} features are consistently vulnerable\")\n",
    "    print(f\"   - Vulnerability rate: {vulnerability_rate:.3f} ({vulnerability_rate*100:.1f}%)\")\n",
    "    \n",
    "    if vulnerability_rate > 0.1:\n",
    "        print(\"   - INTERPRETATION: High feature vulnerability - SAE may be susceptible to attacks\")\n",
    "    elif vulnerability_rate > 0.05:\n",
    "        print(\"   - INTERPRETATION: Moderate vulnerability\")\n",
    "    else:\n",
    "        print(\"   - INTERPRETATION: Low vulnerability - SAE appears robust\")\n",
    "\n",
    "print(\"\\n4. ROBUSTNESS ASSESSMENT:\")\n",
    "if 'successful_results' in locals() and len(successful_results) > 0:\n",
    "    success_rate = len(successful_results) / len(batch_results) if batch_results else 0\n",
    "    print(f\"   - Boundary search success rate: {success_rate:.2f} ({success_rate*100:.1f}%)\")\n",
    "    \n",
    "    if success_rate > 0.8:\n",
    "        print(\"   - INTERPRETATION: Boundaries are easily found - potential robustness concerns\")\n",
    "    elif success_rate > 0.5:\n",
    "        print(\"   - INTERPRETATION: Moderate boundary accessibility\")\n",
    "    else:\n",
    "        print(\"   - INTERPRETATION: Boundaries are hard to find - suggests robustness\")\n",
    "\n",
    "print(\"\\n=== RECOMMENDATIONS ===\")\n",
    "print(\"1. Consider adversarial training to increase boundary distances\")\n",
    "print(\"2. Monitor vulnerable features during deployment\")\n",
    "print(\"3. Test with more diverse text pairs to validate generalization\")\n",
    "print(\"4. Compare with other SAE architectures for robustness benchmarking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdc6661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research Conclusions and Theoretical Interpretations\n",
    "\n",
    "print(\"=== RESEARCH CONCLUSIONS ===\")\n",
    "print()\n",
    "\n",
    "if 'batch_results' in locals() and batch_results and boundary_ratios:\n",
    "    avg_boundary_ratio = np.mean(boundary_ratios)\n",
    "    avg_distance_ratio = np.mean(np.array(hidden_distances) / np.array(sae_distances)) if sae_distances else 0\n",
    "    \n",
    "    print(\"1. POLYTOPE STRUCTURE ANALYSIS:\")\n",
    "    print(f\"   • Average boundary crossing ratio: {avg_boundary_ratio:.2f}\")\n",
    "    \n",
    "    if avg_boundary_ratio > 2:\n",
    "        print(\"   ✓ FINDING: Hidden space traversal crosses MANY SAE decision boundaries\")\n",
    "        print(\"   → INTERPRETATION: SAE creates fine-grained polytope structure\")\n",
    "        print(\"   → IMPLICATION: Concepts are subdivided into multiple SAE regions\")\n",
    "        print(\"   → ROBUSTNESS: More boundaries = more potential attack vectors\")\n",
    "    elif avg_boundary_ratio > 1.2:\n",
    "        print(\"   ✓ FINDING: Hidden space moderately more complex than SAE space\")\n",
    "        print(\"   → INTERPRETATION: SAE provides some structural organization\")\n",
    "        print(\"   → IMPLICATION: Balanced trade-off between compression and structure\")\n",
    "    else:\n",
    "        print(\"   ✓ FINDING: Similar boundary complexity in both spaces\")\n",
    "        print(\"   → INTERPRETATION: SAE preserves geometric structure of hidden space\")\n",
    "        print(\"   → IMPLICATION: Minimal structural reorganization\")\n",
    "    \n",
    "    print(f\"\\n2. DECISION BOUNDARY EFFICIENCY:\")\n",
    "    print(f\"   • Average distance ratio: {avg_distance_ratio:.2f}\")\n",
    "    \n",
    "    if avg_distance_ratio > 1.5:\n",
    "        print(\"   ✓ FINDING: Hidden-to-hidden transitions require larger perturbations\")\n",
    "        print(\"   → INTERPRETATION: SAE provides more direct concept pathways\")\n",
    "        print(\"   → IMPLICATION: SAE may be MORE robust for concept stability\")\n",
    "        print(\"   → SURPRISE: Sparse representation offers better concept separation\")\n",
    "    elif avg_distance_ratio < 0.8:\n",
    "        print(\"   ✓ FINDING: SAE-to-SAE transitions require larger perturbations\")\n",
    "        print(\"   → INTERPRETATION: Hidden space has more direct paths\")\n",
    "        print(\"   → IMPLICATION: SAE may create artificial separation\")\n",
    "    else:\n",
    "        print(\"   ✓ FINDING: Similar perturbation requirements in both spaces\")\n",
    "        print(\"   → INTERPRETATION: Equivalent geometric efficiency\")\n",
    "    \n",
    "    print(f\"\\n3. ROBUSTNESS IMPLICATIONS:\")\n",
    "    \n",
    "    # Analyze vulnerability patterns\n",
    "    min_boundary_crossing = min(boundary_ratios) if boundary_ratios else 0\n",
    "    max_boundary_crossing = max(boundary_ratios) if boundary_ratios else 0\n",
    "    \n",
    "    print(f\"   • Boundary crossing range: {min_boundary_crossing:.2f} to {max_boundary_crossing:.2f}\")\n",
    "    \n",
    "    if max_boundary_crossing > 5:\n",
    "        print(\"   ⚠️  HIGH VULNERABILITY: Some concepts require crossing many boundaries\")\n",
    "        print(\"   → RISK: Complex attack paths but multiple failure points\")\n",
    "    \n",
    "    if min_boundary_crossing < 0.5:\n",
    "        print(\"   ⚠️  LOW VULNERABILITY: Some concepts very close in SAE space\")\n",
    "        print(\"   → RISK: Easy concept confusion with small perturbations\")\n",
    "    \n",
    "    # Success rate analysis\n",
    "    hidden_success_rate = hidden_success/total if 'hidden_success' in locals() and total > 0 else 0\n",
    "    sae_success_rate = sae_success/total if 'sae_success' in locals() and total > 0 else 0\n",
    "    \n",
    "    print(f\"\\n4. ATTACK SUCCESS ANALYSIS:\")\n",
    "    print(f\"   • Hidden space attack success: {hidden_success_rate:.1%}\")\n",
    "    print(f\"   • SAE space attack success: {sae_success_rate:.1%}\")\n",
    "    \n",
    "    if sae_success_rate > hidden_success_rate:\n",
    "        print(\"   ⚠️  SAE space MORE vulnerable to targeted attacks\")\n",
    "        print(\"   → IMPLICATION: Sparse codes easier to manipulate\")\n",
    "    elif hidden_success_rate > sae_success_rate:\n",
    "        print(\"   ✓ SAE space LESS vulnerable to targeted attacks\")\n",
    "        print(\"   → IMPLICATION: Sparsity provides some protection\")\n",
    "    else:\n",
    "        print(\"   → Both spaces show similar attack susceptibility\")\n",
    "\n",
    "print(f\"\\n5. ANSWERS TO RESEARCH QUESTIONS:\")\n",
    "\n",
    "print(f\"\\n   Q1: Do code changes align with crossing ReLU hyperplanes?\")\n",
    "if 'boundary_result' in locals():\n",
    "    print(f\"   ✓ YES: DeepFool successfully found exact decision boundaries\")\n",
    "    print(f\"   → Boundary distance: {boundary_result.delta_min:.6f}\")\n",
    "    print(f\"   → Feature flips: {len(boundary_result.flipped_features)}\")\n",
    "\n",
    "print(f\"\\n   Q2: How many intermediate boundaries separate concepts?\")\n",
    "if boundary_ratios:\n",
    "    print(f\"   ✓ ANSWER: {avg_boundary_ratio:.1f} SAE boundaries on average\")\n",
    "    print(f\"   → Range: {min_boundary_crossing:.1f} to {max_boundary_crossing:.1f}\")\n",
    "    if avg_boundary_ratio > 3:\n",
    "        print(\"   → CONCLUSION: Concepts well-separated by multiple boundaries\")\n",
    "    elif avg_boundary_ratio > 1:\n",
    "        print(\"   → CONCLUSION: Moderate separation with some intermediate structure\")\n",
    "    else:\n",
    "        print(\"   → CONCLUSION: Direct transitions possible between concepts\")\n",
    "\n",
    "print(f\"\\n6. METHODOLOGICAL VALIDATION:\")\n",
    "print(f\"   ✓ DeepFool adaptation successfully finds minimal perturbations\")\n",
    "print(f\"   ✓ Boundary counting provides quantitative complexity measure\")\n",
    "print(f\"   ✓ Hidden vs SAE comparison reveals structural differences\")\n",
    "print(f\"   ✓ Statistical analysis enables generalization beyond single examples\")\n",
    "\n",
    "print(f\"\\n=== FUTURE RESEARCH DIRECTIONS ===\")\n",
    "print(f\"1. Test with larger concept vocabularies (beyond education/technology)\")\n",
    "print(f\"2. Analyze boundary density as function of SAE width/sparsity\")\n",
    "print(f\"3. Develop adversarial defenses based on boundary distance metrics\")\n",
    "print(f\"4. Compare different SAE architectures (standard vs. TopK vs. Gated)\")\n",
    "print(f\"5. Investigate relationship between boundary crossing and semantic similarity\")\n",
    "\n",
    "else:\n",
    "    print(\"Please run the experiments above to generate conclusions.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 4: Visualization of Boundary Crossing Analysis\n",
    "\n",
    "print(\"=== EXPERIMENT 4: VISUALIZATION ===\")\n",
    "\n",
    "# Create comprehensive visualization\n",
    "if 'batch_results' in locals() and batch_results:\n",
    "    print(\"Creating boundary crossing comparison plots...\")\n",
    "    \n",
    "    # Use the specialized visualization function\n",
    "    visualize_boundary_comparison(batch_results, save_path='boundary_comparison.png')\n",
    "    \n",
    "    # Additional analysis plot\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot 1: Boundary trajectory comparison\n",
    "    plt.subplot(1, 3, 1)\n",
    "    if boundary_ratios:\n",
    "        plt.hist(boundary_ratios, bins=max(10, len(boundary_ratios)), alpha=0.7, edgecolor='black')\n",
    "        plt.axvline(x=1.0, color='red', linestyle='--', alpha=0.7, label='Equal complexity')\n",
    "        plt.axvline(x=np.mean(boundary_ratios), color='blue', linestyle='-', alpha=0.7, label=f'Mean: {np.mean(boundary_ratios):.2f}')\n",
    "        plt.xlabel('Boundary Ratio (Hidden/SAE)')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Complexity Ratio Distribution')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Distance vs Boundary Count\n",
    "    plt.subplot(1, 3, 2)\n",
    "    if hidden_distances and hidden_boundaries:\n",
    "        plt.scatter(hidden_distances, hidden_boundaries, alpha=0.7, label='Hidden space', color='blue')\n",
    "        plt.scatter(sae_distances, sae_boundaries, alpha=0.7, label='SAE space', color='orange')\n",
    "        plt.xlabel('Perturbation Distance')\n",
    "        plt.ylabel('Boundaries Crossed')\n",
    "        plt.title('Distance vs Boundary Complexity')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Success rate comparison\n",
    "    plt.subplot(1, 3, 3)\n",
    "    hidden_success = sum(1 for data in batch_results.values() if data['hidden_transition'].target_reached)\n",
    "    sae_success = sum(1 for data in batch_results.values() if data['sae_transition'].target_reached)\n",
    "    total = len(batch_results)\n",
    "    \n",
    "    categories = ['Hidden\\nSpace', 'SAE\\nSpace']\n",
    "    success_rates = [hidden_success/total if total > 0 else 0, sae_success/total if total > 0 else 0]\n",
    "    colors = ['skyblue', 'orange']\n",
    "    \n",
    "    bars = plt.bar(categories, success_rates, alpha=0.7, color=colors)\n",
    "    plt.ylabel('Success Rate')\n",
    "    plt.title('Transition Success Rates')\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, rate in zip(bars, success_rates):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                f'{rate:.1%}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics table\n",
    "    print(f\"\\n=== FINAL SUMMARY TABLE ===\")\n",
    "    print(\"Metric                    | Hidden Space | SAE Space   | Ratio (H/S)\")\n",
    "    print(\"-\" * 65)\n",
    "    print(f\"Avg. Distance             | {np.mean(hidden_distances):8.4f}   | {np.mean(sae_distances):7.4f}   | {np.mean(hidden_distances)/np.mean(sae_distances):6.2f}\")\n",
    "    print(f\"Avg. Boundaries Crossed   | {np.mean(hidden_boundaries):8.1f}   | {np.mean(sae_boundaries):7.1f}   | {np.mean(boundary_ratios):6.2f}\")\n",
    "    print(f\"Success Rate              | {hidden_success/total:8.1%}   | {sae_success/total:7.1%}   | {(hidden_success/sae_success if sae_success > 0 else float('inf')):6.2f}\")\n",
    "    print(f\"Std. Distance             | {np.std(hidden_distances):8.4f}   | {np.std(sae_distances):7.4f}   | {np.std(hidden_distances)/np.std(sae_distances):6.2f}\")\n",
    "\n",
    "else:\n",
    "    print(\"No batch results available for visualization.\")\n",
    "    print(\"Please run the previous experiments first.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1c667b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 3: Batch Analysis of Concept Transitions\n",
    "# Analyze multiple concept pairs to get statistical insights\n",
    "\n",
    "print(\"=== EXPERIMENT 3: BATCH CONCEPT TRANSITION ANALYSIS ===\")\n",
    "\n",
    "# Create concept pairs\n",
    "concept_pairs = [\n",
    "    (education_texts[0], technology_texts[0]),\n",
    "    (education_texts[1], technology_texts[1]),\n",
    "    (education_texts[2], technology_texts[2])\n",
    "]\n",
    "\n",
    "print(f\"Analyzing {len(concept_pairs)} concept pairs...\")\n",
    "print(\"This will compare hidden-space vs SAE-space transitions for each pair\")\n",
    "print()\n",
    "\n",
    "# Run batch analysis\n",
    "batch_results = tracer.analyze_concept_transitions_batch(\n",
    "    concept_pairs=concept_pairs,\n",
    "    layer_idx=layer_num,\n",
    "    max_iter=100,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\n=== BATCH ANALYSIS RESULTS ===\")\n",
    "print(f\"Successfully analyzed: {len(batch_results)} pairs\")\n",
    "\n",
    "# Collect statistics\n",
    "hidden_distances = []\n",
    "sae_distances = []\n",
    "boundary_ratios = []\n",
    "hidden_boundaries = []\n",
    "sae_boundaries = []\n",
    "\n",
    "for pair_key, data in batch_results.items():\n",
    "    hidden_res = data['hidden_transition']\n",
    "    sae_res = data['sae_transition']\n",
    "    \n",
    "    hidden_distances.append(hidden_res.delta_min)\n",
    "    sae_distances.append(sae_res.delta_min)\n",
    "    hidden_boundaries.append(hidden_res.num_boundaries_crossed)\n",
    "    sae_boundaries.append(sae_res.num_boundaries_crossed)\n",
    "    boundary_ratios.append(data['boundary_ratio'])\n",
    "    \n",
    "    print(f\"\\n{pair_key}:\")\n",
    "    print(f\"  Hidden: {hidden_res.delta_min:.4f} (boundaries: {hidden_res.num_boundaries_crossed})\")\n",
    "    print(f\"  SAE:    {sae_res.delta_min:.4f} (boundaries: {sae_res.num_boundaries_crossed})\")\n",
    "    print(f\"  Ratio:  {data['boundary_ratio']:.2f}\")\n",
    "\n",
    "if hidden_distances and sae_distances:\n",
    "    print(f\"\\n=== STATISTICAL SUMMARY ===\")\n",
    "    print(f\"Hidden space distances:\")\n",
    "    print(f\"  - Mean: {np.mean(hidden_distances):.6f}\")\n",
    "    print(f\"  - Std:  {np.std(hidden_distances):.6f}\")\n",
    "    print(f\"  - Range: {np.min(hidden_distances):.6f} to {np.max(hidden_distances):.6f}\")\n",
    "    \n",
    "    print(f\"\\nSAE space distances:\")\n",
    "    print(f\"  - Mean: {np.mean(sae_distances):.6f}\")\n",
    "    print(f\"  - Std:  {np.std(sae_distances):.6f}\")\n",
    "    print(f\"  - Range: {np.min(sae_distances):.6f} to {np.max(sae_distances):.6f}\")\n",
    "    \n",
    "    print(f\"\\nBoundary crossings:\")\n",
    "    print(f\"  - Hidden space: {np.mean(hidden_boundaries):.1f} ± {np.std(hidden_boundaries):.1f}\")\n",
    "    print(f\"  - SAE space: {np.mean(sae_boundaries):.1f} ± {np.std(sae_boundaries):.1f}\")\n",
    "    print(f\"  - Average ratio: {np.mean(boundary_ratios):.2f}\")\n",
    "    \n",
    "    # Key research insights\n",
    "    avg_boundary_ratio = np.mean(boundary_ratios)\n",
    "    avg_distance_ratio = np.mean(np.array(hidden_distances) / np.array(sae_distances))\n",
    "    \n",
    "    print(f\"\\n=== RESEARCH INSIGHTS ===\")\n",
    "    print(f\"1. BOUNDARY COMPLEXITY:\")\n",
    "    if avg_boundary_ratio > 2:\n",
    "        print(f\"   → Hidden space transitions cross {avg_boundary_ratio:.1f}x more SAE boundaries\")\n",
    "        print(\"   → SAE creates complex intermediate structure\")\n",
    "    elif avg_boundary_ratio > 1.2:\n",
    "        print(f\"   → Hidden space moderately more complex ({avg_boundary_ratio:.1f}x boundaries)\")\n",
    "        print(\"   → SAE introduces some structural organization\")\n",
    "    else:\n",
    "        print(f\"   → Similar boundary complexity ({avg_boundary_ratio:.1f}x)\")\n",
    "        print(\"   → SAE preserves hidden space structure\")\n",
    "    \n",
    "    print(f\"\\n2. DISTANCE EFFICIENCY:\")\n",
    "    if avg_distance_ratio > 1.5:\n",
    "        print(f\"   → Hidden transitions require {avg_distance_ratio:.1f}x larger perturbations\")\n",
    "        print(\"   → SAE provides more direct paths between concepts\")\n",
    "    elif avg_distance_ratio < 0.8:\n",
    "        print(f\"   → SAE transitions require {1/avg_distance_ratio:.1f}x larger perturbations\")\n",
    "        print(\"   → Hidden space provides more direct paths\")\n",
    "    else:\n",
    "        print(f\"   → Similar perturbation requirements ({avg_distance_ratio:.1f}x)\")\n",
    "        print(\"   → Both spaces have comparable path efficiency\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed21dc04",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'education_texts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Batch analysis for multiple texts\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m all_texts \u001b[38;5;241m=\u001b[39m \u001b[43meducation_texts\u001b[49m \u001b[38;5;241m+\u001b[39m technology_texts\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnalyzing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(all_texts)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m texts for boundary distances...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Run batch analysis (this might take a while)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'education_texts' is not defined"
     ]
    }
   ],
   "source": [
    "# Experiment 2: Concept Transition Analysis\n",
    "# Compare hidden-to-hidden vs SAE-to-SAE transitions\n",
    "\n",
    "print(\"=== EXPERIMENT 2: CONCEPT TRANSITION ANALYSIS ===\")\n",
    "print(\"Comparing:\")\n",
    "print(\"1. Hidden space: source_hidden → target_hidden (counting SAE boundary crossings)\")  \n",
    "print(\"2. SAE space: source_hidden → target_SAE_code\")\n",
    "print()\n",
    "\n",
    "# Analyze single concept pair\n",
    "source_text = education_texts[0]\n",
    "target_text = technology_texts[0]\n",
    "\n",
    "print(f\"Source concept: '{source_text[:50]}...'\")\n",
    "print(f\"Target concept: '{target_text[:50]}...'\")\n",
    "print()\n",
    "\n",
    "# Run targeted concept transition analysis\n",
    "print(\"Running targeted transition analysis...\")\n",
    "hidden_result, sae_result = tracer.targeted_concept_transition(\n",
    "    source_text=source_text,\n",
    "    target_text=target_text,\n",
    "    layer_idx=layer_num,\n",
    "    max_iter=100,  # Reduced for testing\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\n=== TRANSITION COMPARISON RESULTS ===\")\n",
    "\n",
    "print(f\"\\n1. HIDDEN SPACE TRANSITION (source_hidden → target_hidden):\")\n",
    "print(f\"   - Perturbation magnitude: {hidden_result.delta_min:.6f}\")\n",
    "print(f\"   - SAE boundaries crossed: {hidden_result.num_boundaries_crossed}\")\n",
    "print(f\"   - Target reached: {hidden_result.target_reached}\")\n",
    "print(f\"   - Optimization steps: {hidden_result.num_steps}\")\n",
    "\n",
    "print(f\"\\n2. SAE SPACE TRANSITION (source_hidden → target_SAE_code):\")\n",
    "print(f\"   - Perturbation magnitude: {sae_result.delta_min:.6f}\")\n",
    "print(f\"   - Boundaries crossed: {sae_result.num_boundaries_crossed}\")\n",
    "print(f\"   - Target reached: {sae_result.target_reached}\")\n",
    "print(f\"   - Optimization steps: {sae_result.num_steps}\")\n",
    "\n",
    "# Key insight: boundary crossing comparison\n",
    "if hidden_result.num_boundaries_crossed > 0 and sae_result.num_boundaries_crossed > 0:\n",
    "    boundary_ratio = hidden_result.num_boundaries_crossed / sae_result.num_boundaries_crossed\n",
    "    print(f\"\\n=== KEY INSIGHT ===\")\n",
    "    print(f\"Boundary crossing ratio (Hidden/SAE): {boundary_ratio:.2f}\")\n",
    "    \n",
    "    if boundary_ratio > 2:\n",
    "        print(\"→ Hidden space requires crossing MANY more SAE boundaries\")\n",
    "        print(\"  This suggests SAE creates a complex intermediate representation\")\n",
    "    elif boundary_ratio > 1.2:\n",
    "        print(\"→ Hidden space requires moderately more SAE boundaries\")\n",
    "        print(\"  This suggests some intermediate structure in SAE space\")\n",
    "    else:\n",
    "        print(\"→ Hidden and SAE space have similar boundary complexity\")\n",
    "        print(\"  This suggests SAE preserves the structure of hidden space\")\n",
    "\n",
    "# Compare perturbation magnitudes\n",
    "distance_ratio = hidden_result.delta_min / sae_result.delta_min if sae_result.delta_min > 0 else float('inf')\n",
    "print(f\"\\nDistance ratio (Hidden/SAE): {distance_ratio:.2f}\")\n",
    "\n",
    "if distance_ratio > 1.5:\n",
    "    print(\"→ Hidden space transitions require LARGER perturbations\")\n",
    "elif distance_ratio < 0.8:\n",
    "    print(\"→ SAE space transitions require LARGER perturbations\")\n",
    "else:\n",
    "    print(\"→ Both transitions require similar perturbation magnitudes\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3476eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1: DeepFool-style Nearest Boundary Search\n",
    "# Find minimal perturbation to cross the nearest SAE decision boundary\n",
    "\n",
    "print(\"=== EXPERIMENT 1: NEAREST BOUNDARY ANALYSIS ===\")\n",
    "\n",
    "# Test with a single example first\n",
    "test_text = education_texts[0]\n",
    "print(f\"Testing with: '{test_text}'\")\n",
    "\n",
    "# Extract hidden representation\n",
    "hidden_state = tracer.get_hidden_representation(test_text, layer_num)\n",
    "print(f\"Hidden state shape: {hidden_state.shape}\")\n",
    "\n",
    "# Get original SAE code\n",
    "original_code = tracer.get_sae_code(hidden_state)\n",
    "original_active = (original_code > 0).sum().item()\n",
    "print(f\"Original code has {original_active} active features out of {len(original_code)}\")\n",
    "\n",
    "# Find nearest boundary using DeepFool approach\n",
    "print(\"\\nFinding nearest decision boundary...\")\n",
    "boundary_result = tracer.find_nearest_boundary_deepfool(\n",
    "    hidden_state, \n",
    "    max_iter=50,\n",
    "    overshoot=0.02,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\n=== BOUNDARY ANALYSIS RESULTS ===\")\n",
    "print(f\"Minimal perturbation norm ||δ_min||: {boundary_result.delta_min:.6f}\")\n",
    "print(f\"Boundary successfully crossed: {boundary_result.target_reached}\")\n",
    "print(f\"Number of DeepFool iterations: {boundary_result.num_steps}\")\n",
    "print(f\"Features that flipped: {len(boundary_result.flipped_features)}\")\n",
    "\n",
    "if boundary_result.flipped_features:\n",
    "    print(\"Feature flip details:\")\n",
    "    for feature_idx, flip_type in boundary_result.flipped_features[:5]:  # Show first 5\n",
    "        print(f\"  - Feature {feature_idx}: {flip_type}\")\n",
    "\n",
    "# Compare original vs perturbed codes\n",
    "print(f\"\\nOriginal active features: {original_active}\")\n",
    "perturbed_active = (boundary_result.perturbed_code > 0).sum().item()\n",
    "print(f\"Perturbed active features: {perturbed_active}\")\n",
    "print(f\"Net change in active features: {perturbed_active - original_active}\")\n",
    "\n",
    "# Analyze perturbation direction\n",
    "perturbation_norm = boundary_result.perturbation.norm().item()\n",
    "hidden_norm = hidden_state.norm().item()\n",
    "relative_perturbation = perturbation_norm / hidden_norm\n",
    "print(f\"\\nPerturbation analysis:\")\n",
    "print(f\"  - Perturbation magnitude: {perturbation_norm:.6f}\")\n",
    "print(f\"  - Hidden state magnitude: {hidden_norm:.2f}\")\n",
    "print(f\"  - Relative perturbation: {relative_perturbation:.4f} ({relative_perturbation*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7ec85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the improved boundary crossing analysis\n",
    "from boundary_crossing_fixed import SAEBoundaryTracer, visualize_boundary_comparison\n",
    "\n",
    "# Initialize the boundary tracer\n",
    "tracer = SAEBoundaryTracer(sae, tokenizer, model, device=device)\n",
    "\n",
    "# Example texts for concept transition analysis\n",
    "education_texts = [\n",
    "    \"The university offers comprehensive programs in computer science and engineering.\",\n",
    "    \"Students can pursue advanced degrees in mathematics and physics.\",\n",
    "    \"The curriculum includes hands-on laboratory experiences and research opportunities.\"\n",
    "]\n",
    "\n",
    "technology_texts = [\n",
    "    \"The new smartphone features advanced AI capabilities and improved battery life.\",\n",
    "    \"Cloud computing platforms enable scalable and efficient data processing.\",\n",
    "    \"Machine learning algorithms are revolutionizing industries across the globe.\"\n",
    "]\n",
    "\n",
    "print(\"=== IMPROVED SAE BOUNDARY CROSSING ANALYSIS ===\")\n",
    "print(\"This implementation addresses:\")\n",
    "print(\"1. DeepFool-style minimal perturbation finding\")\n",
    "print(\"2. Hidden-to-hidden vs SAE-to-SAE transition comparison\")\n",
    "print(\"3. Boundary counting for intermediate crossings\")\n",
    "print(\"4. Exact decision boundary identification\")\n",
    "print()\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b34cef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concept Distance Analysis: Education vs Technology\n",
    "# Measure how many boundaries need to be crossed to go from one concept to another\n",
    "\n",
    "concept_pairs = [\n",
    "    (education_texts[0], technology_texts[0]),\n",
    "]\n",
    "\n",
    "print(\"Analyzing concept distances between education and technology...\")\n",
    "print(f\"Number of concept pairs: {len(concept_pairs)}\")\n",
    "\n",
    "# Run concept distance analysis\n",
    "concept_results = tracer.concept_distance_analysis(\n",
    "    concept_pairs,\n",
    "    layer_idx=layer_num,\n",
    "    max_iterations=100  # More iterations for targeted search\n",
    ")\n",
    "\n",
    "print(f\"\\nConcept Distance Results:\")\n",
    "for pair_key, data in concept_results.items():\n",
    "    print(f\"\\n{pair_key}:\")\n",
    "    print(f\"  Education → Technology: {data['a_to_b_distance']:.6f} (reached: {data['a_to_b_reached']})\")\n",
    "    print(f\"  Technology → Education: {data['b_to_a_distance']:.6f} (reached: {data['b_to_a_reached']})\")\n",
    "    print(f\"  Education boundary distance: {data['a_boundary_distance']:.6f}\")\n",
    "    print(f\"  Technology boundary distance: {data['b_boundary_distance']:.6f}\")\n",
    "    \n",
    "    if data['distance_ratio_a'] != float('inf'):\n",
    "        print(f\"  Education concept distance ratio: {data['distance_ratio_a']:.2f}x single boundary\")\n",
    "    if data['distance_ratio_b'] != float('inf'):\n",
    "        print(f\"  Technology concept distance ratio: {data['distance_ratio_b']:.2f}x single boundary\")\n",
    "\n",
    "# Summary statistics\n",
    "all_concept_distances = []\n",
    "all_boundary_distances = []\n",
    "all_ratios = []\n",
    "\n",
    "for data in concept_results.values():\n",
    "    all_concept_distances.extend([data['a_to_b_distance'], data['b_to_a_distance']])\n",
    "    all_boundary_distances.extend([data['a_boundary_distance'], data['b_boundary_distance']])\n",
    "    if data['distance_ratio_a'] != float('inf'):\n",
    "        all_ratios.append(data['distance_ratio_a'])\n",
    "    if data['distance_ratio_b'] != float('inf'):\n",
    "        all_ratios.append(data['distance_ratio_b'])\n",
    "\n",
    "print(f\"\\nOverall Summary:\")\n",
    "print(f\"- Mean concept distance: {np.mean(all_concept_distances):.6f}\")\n",
    "print(f\"- Mean single boundary distance: {np.mean(all_boundary_distances):.6f}\")\n",
    "if all_ratios:\n",
    "    print(f\"- Mean distance ratio: {np.mean(all_ratios):.2f}x\")\n",
    "    print(f\"- This suggests concepts are {np.mean(all_ratios):.1f}x farther apart than single boundaries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278c3aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c735c3de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271721ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRECTED: Hidden Space Polytope Boundary Analysis\n",
    "# This fixes the fundamental error in _targeted_transition_hidden\n",
    "\n",
    "print(\"=== CORRECTED HIDDEN SPACE POLYTOPE ANALYSIS ===\")\n",
    "print(\"ISSUE FOUND: Previous implementation tracked SAE boundary crossings\")\n",
    "print(\"CORRECTION: Now tracking ReLU polytope boundaries in HIDDEN space\")\n",
    "print()\n",
    "\n",
    "def analyze_hidden_polytope_transition(\n",
    "    source_hidden: torch.Tensor,\n",
    "    target_hidden: torch.Tensor,\n",
    "    max_iter: int = 200,\n",
    "    step_size: float = 0.01,\n",
    "    verbose: bool = True\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Correct implementation: Track ReLU polytope boundaries in HIDDEN space.\n",
    "    \n",
    "    The polytope in hidden space is defined by h_i > 0 for each dimension i.\n",
    "    We count how many times we cross hyperplanes h_i = 0 during optimization.\n",
    "    \"\"\"\n",
    "    \n",
    "    delta = torch.zeros_like(source_hidden, requires_grad=True)\n",
    "    optimizer = torch.optim.Adam([delta], lr=step_size)\n",
    "    \n",
    "    # Track HIDDEN space polytope changes (not SAE)\n",
    "    original_hidden_polytope = (source_hidden > 0).float()\n",
    "    previous_hidden_polytope = original_hidden_polytope.clone()\n",
    "    boundary_count = 0\n",
    "    trajectory = []\n",
    "    \n",
    "    best_delta = None\n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    for step in range(max_iter):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        current_hidden = source_hidden + delta\n",
    "        \n",
    "        # Count ReLU polytope boundary crossings in HIDDEN space\n",
    "        current_hidden_polytope = (current_hidden > 0).float()\n",
    "        \n",
    "        # Check if we crossed any hyperplane h_i = 0\n",
    "        if not torch.equal(current_hidden_polytope, previous_hidden_polytope):\n",
    "            boundary_count += 1\n",
    "            \n",
    "            # Identify which dimensions crossed zero\n",
    "            differences = current_hidden_polytope - previous_hidden_polytope\n",
    "            activated_dims = (differences > 0).nonzero(as_tuple=True)[0]\n",
    "            deactivated_dims = (differences < 0).nonzero(as_tuple=True)[0]\n",
    "            \n",
    "            if verbose and step % 20 == 0:\n",
    "                print(f\"Step {step}: Hidden polytope boundary #{boundary_count}\")\n",
    "                if len(activated_dims) > 0:\n",
    "                    print(f\"  Activated dimensions: {activated_dims[:5].tolist()}...\")\n",
    "                if len(deactivated_dims) > 0:\n",
    "                    print(f\"  Deactivated dimensions: {deactivated_dims[:5].tolist()}...\")\n",
    "        \n",
    "        previous_hidden_polytope = current_hidden_polytope.clone()\n",
    "        \n",
    "        # Loss: L2 distance to target hidden state\n",
    "        loss = F.mse_loss(current_hidden, target_hidden)\n",
    "        \n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            best_delta = delta.detach().clone()\n",
    "        \n",
    "        # Check convergence\n",
    "        if loss.item() < 1e-6:\n",
    "            if verbose:\n",
    "                print(f\"Target reached at step {step}\")\n",
    "            break\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        trajectory.append(delta.detach().clone())\n",
    "        \n",
    "        if verbose and step % 50 == 0:\n",
    "            print(f\"Step {step}: loss = {loss.item():.6f}, ||δ|| = {delta.norm().item():.6f}, boundaries = {boundary_count}\")\n",
    "    \n",
    "    return {\n",
    "        'delta_min': best_delta.norm().item(),\n",
    "        'perturbation': best_delta,\n",
    "        'num_steps': step,\n",
    "        'hidden_polytope_boundaries_crossed': boundary_count,\n",
    "        'target_reached': best_loss < 1e-3,\n",
    "        'final_loss': best_loss,\n",
    "        'trajectory': trajectory\n",
    "    }\n",
    "\n",
    "# Test with single concept pair\n",
    "source_text = education_texts[0]\n",
    "target_text = technology_texts[0]\n",
    "\n",
    "print(f\"Source: '{source_text[:50]}...'\")\n",
    "print(f\"Target: '{target_text[:50]}...'\")\n",
    "print()\n",
    "\n",
    "# Get hidden representations\n",
    "source_hidden = tracer.get_hidden_representation(source_text, layer_num)\n",
    "target_hidden = tracer.get_hidden_representation(target_text, layer_num)\n",
    "\n",
    "print(f\"Source hidden shape: {source_hidden.shape}\")\n",
    "print(f\"Target hidden shape: {target_hidden.shape}\")\n",
    "\n",
    "# Original polytope analysis\n",
    "source_polytope = (source_hidden > 0).float()\n",
    "target_polytope = (target_hidden > 0).float()\n",
    "polytope_hamming = (source_polytope != target_polytope).sum().item()\n",
    "\n",
    "print(f\"Source polytope active dims: {source_polytope.sum().item()}/{len(source_polytope)}\")\n",
    "print(f\"Target polytope active dims: {target_polytope.sum().item()}/{len(target_polytope)}\")\n",
    "print(f\"Polytope Hamming distance: {polytope_hamming}\")\n",
    "print()\n",
    "\n",
    "# Run corrected analysis\n",
    "print(\"Running CORRECTED hidden polytope transition analysis...\")\n",
    "result = analyze_hidden_polytope_transition(\n",
    "    source_hidden, target_hidden, \n",
    "    max_iter=100, \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\n=== CORRECTED RESULTS ===\")\n",
    "print(f\"Minimal perturbation: {result['delta_min']:.6f}\")\n",
    "print(f\"Hidden polytope boundaries crossed: {result['hidden_polytope_boundaries_crossed']}\")\n",
    "print(f\"Target reached: {result['target_reached']}\")\n",
    "print(f\"Final loss: {result['final_loss']:.6f}\")\n",
    "print(f\"Optimization steps: {result['num_steps']}\")\n",
    "\n",
    "# Compare with SAE boundary counting for perspective\n",
    "original_sae_code = tracer.get_sae_code(source_hidden)\n",
    "final_sae_code = tracer.get_sae_code(source_hidden + result['perturbation'])\n",
    "sae_changes = ((original_sae_code > 0).float() != (final_sae_code > 0).float()).sum().item()\n",
    "\n",
    "print(f\"\\nFor comparison:\")\n",
    "print(f\"SAE feature changes during this transition: {sae_changes}\")\n",
    "print(f\"Hidden polytope boundaries crossed: {result['hidden_polytope_boundaries_crossed']}\")\n",
    "print(f\"Ratio (Hidden boundaries / SAE changes): {result['hidden_polytope_boundaries_crossed'] / max(sae_changes, 1):.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"KEY INSIGHT:\")\n",
    "print(\"Now we're properly measuring transitions between\")\n",
    "print(\"ReLU polytopes in the HIDDEN space (h_i > 0),\")\n",
    "print(\"not SAE feature boundaries!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1febfd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARISON: Wrong vs Correct Boundary Tracking\n",
    "# Demonstrates the difference between the flawed and correct approaches\n",
    "\n",
    "print(\"=== COMPARISON: WRONG vs CORRECT BOUNDARY TRACKING ===\")\n",
    "print()\n",
    "\n",
    "def analyze_transition_wrong_way(\n",
    "    source_hidden: torch.Tensor,\n",
    "    target_hidden: torch.Tensor,\n",
    "    sae_model,\n",
    "    max_iter: int = 100,\n",
    "    step_size: float = 0.01\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    WRONG WAY: Track SAE boundary crossings during hidden-to-hidden transition.\n",
    "    This is what the original implementation was doing incorrectly.\n",
    "    \"\"\"\n",
    "    \n",
    "    delta = torch.zeros_like(source_hidden, requires_grad=True)\n",
    "    optimizer = torch.optim.Adam([delta], lr=step_size)\n",
    "    \n",
    "    # WRONG: Track SAE code changes during hidden space transition\n",
    "    original_sae_code = tracer.get_sae_code(source_hidden)\n",
    "    previous_sae_code = original_sae_code.clone()\n",
    "    sae_boundary_count = 0\n",
    "    \n",
    "    best_delta = None\n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    for step in range(max_iter):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        current_hidden = source_hidden + delta\n",
    "        \n",
    "        # WRONG: Monitor SAE code changes instead of hidden polytope\n",
    "        current_sae_code = tracer.get_sae_code(current_hidden)\n",
    "        if not torch.equal((current_sae_code > 0).float(), (previous_sae_code > 0).float()):\n",
    "            sae_boundary_count += 1\n",
    "        \n",
    "        previous_sae_code = current_sae_code.clone()\n",
    "        \n",
    "        # Loss: L2 distance to target\n",
    "        loss = F.mse_loss(current_hidden, target_hidden)\n",
    "        \n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            best_delta = delta.detach().clone()\n",
    "        \n",
    "        if loss.item() < 1e-6:\n",
    "            break\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return {\n",
    "        'delta_min': best_delta.norm().item(),\n",
    "        'sae_boundaries_crossed': sae_boundary_count,  # WRONG metric\n",
    "        'target_reached': best_loss < 1e-3,\n",
    "        'num_steps': step\n",
    "    }\n",
    "\n",
    "def analyze_transition_correct_way(\n",
    "    source_hidden: torch.Tensor,\n",
    "    target_hidden: torch.Tensor,\n",
    "    max_iter: int = 100,\n",
    "    step_size: float = 0.01\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    CORRECT WAY: Track hidden polytope boundary crossings (h_i = 0).\n",
    "    \"\"\"\n",
    "    \n",
    "    delta = torch.zeros_like(source_hidden, requires_grad=True)\n",
    "    optimizer = torch.optim.Adam([delta], lr=step_size)\n",
    "    \n",
    "    # CORRECT: Track hidden polytope changes\n",
    "    original_hidden_polytope = (source_hidden > 0).float()\n",
    "    previous_hidden_polytope = original_hidden_polytope.clone()\n",
    "    hidden_polytope_boundary_count = 0\n",
    "    \n",
    "    best_delta = None\n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    for step in range(max_iter):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        current_hidden = source_hidden + delta\n",
    "        \n",
    "        # CORRECT: Monitor hidden polytope changes (h_i > 0)\n",
    "        current_hidden_polytope = (current_hidden > 0).float()\n",
    "        if not torch.equal(current_hidden_polytope, previous_hidden_polytope):\n",
    "            hidden_polytope_boundary_count += 1\n",
    "        \n",
    "        previous_hidden_polytope = current_hidden_polytope.clone()\n",
    "        \n",
    "        # Loss: L2 distance to target\n",
    "        loss = F.mse_loss(current_hidden, target_hidden)\n",
    "        \n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            best_delta = delta.detach().clone()\n",
    "        \n",
    "        if loss.item() < 1e-6:\n",
    "            break\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return {\n",
    "        'delta_min': best_delta.norm().item(),\n",
    "        'hidden_polytope_boundaries_crossed': hidden_polytope_boundary_count,  # CORRECT metric\n",
    "        'target_reached': best_loss < 1e-3,\n",
    "        'num_steps': step\n",
    "    }\n",
    "\n",
    "print(\"Testing both approaches on the same transition...\")\n",
    "print(f\"Education → Technology concept transition\")\n",
    "print()\n",
    "\n",
    "# Run wrong approach\n",
    "print(\"1. WRONG APPROACH (tracking SAE boundaries):\")\n",
    "wrong_result = analyze_transition_wrong_way(\n",
    "    source_hidden, target_hidden, tracer.sae\n",
    ")\n",
    "print(f\"   - Perturbation magnitude: {wrong_result['delta_min']:.6f}\")\n",
    "print(f\"   - SAE boundaries crossed: {wrong_result['sae_boundaries_crossed']}\")\n",
    "print(f\"   - Target reached: {wrong_result['target_reached']}\")\n",
    "\n",
    "# Run correct approach  \n",
    "print(\"\\n2. CORRECT APPROACH (tracking hidden polytope boundaries):\")\n",
    "correct_result = analyze_transition_correct_way(\n",
    "    source_hidden, target_hidden\n",
    ")\n",
    "print(f\"   - Perturbation magnitude: {correct_result['delta_min']:.6f}\")\n",
    "print(f\"   - Hidden polytope boundaries crossed: {correct_result['hidden_polytope_boundaries_crossed']}\")\n",
    "print(f\"   - Target reached: {correct_result['target_reached']}\")\n",
    "\n",
    "print(f\"\\n=== CRITICAL COMPARISON ===\")\n",
    "print(f\"Wrong method counted: {wrong_result['sae_boundaries_crossed']} 'boundaries'\")\n",
    "print(f\"Correct method counted: {correct_result['hidden_polytope_boundaries_crossed']} boundaries\")\n",
    "print()\n",
    "print(\"EXPLANATION:\")\n",
    "print(\"- Wrong method: Counts when SAE features flip during hidden→hidden transition\")\n",
    "print(\"- Correct method: Counts when hidden dimensions cross h_i = 0 hyperplanes\")\n",
    "print()\n",
    "print(\"The wrong method conflates two different spaces:\")\n",
    "print(\"  • Hidden space polytopes (defined by h_i > 0)\")  \n",
    "print(\"  • SAE feature space (defined by f_i > 0 where f = ReLU(Wh + b))\")\n",
    "print()\n",
    "print(\"For polytope analysis, we want HIDDEN space boundaries, not SAE boundaries!\")\n",
    "print()\n",
    "\n",
    "# Show what the numbers mean\n",
    "print(\"=== INTERPRETATION ===\")\n",
    "if correct_result['hidden_polytope_boundaries_crossed'] > 0:\n",
    "    print(f\"The transition from education→technology concepts\")\n",
    "    print(f\"requires crossing {correct_result['hidden_polytope_boundaries_crossed']} hyperplanes in the hidden space\")\n",
    "    print(f\"where individual hidden dimensions change sign (h_i: positive ↔ negative)\")\n",
    "else:\n",
    "    print(\"The transition stays within the same polytope region!\")\n",
    "    print(\"(No hidden dimensions changed sign)\")\n",
    "print()\n",
    "\n",
    "print(\"This is the CORRECT way to measure polytope complexity!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sae_clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
